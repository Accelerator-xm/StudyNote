{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f98a700",
   "metadata": {},
   "source": [
    "# 线性代数\n",
    "\n",
    "## 标量\n",
    "\n",
    "**标量**由只有**一个元素**的张量表示，变量通常用小写字母表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d462f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(1.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "(x+y, x-y, x*y, x/y, x**y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea72916",
   "metadata": {},
   "source": [
    "## 向量\n",
    "\n",
    "**向量**为1维张量，可以看成一组标量的列表，一般默认为列向量，标量值称为**元素**或**分量(component)**，通常用小写字母粗体表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88dbf323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03566b",
   "metadata": {},
   "source": [
    "可以通过下标引用向量的任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d68dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e5fa8",
   "metadata": {},
   "source": [
    "向量的长度称为向量的**度(dim)**：表示元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7468bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc773f98",
   "metadata": {},
   "source": [
    "向量是1维的张量，也可以用shape访问向量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e1a0ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700d2d4",
   "metadata": {},
   "source": [
    "## 矩阵\n",
    "\n",
    "**矩阵**为2维张量，可以看成一个表格，通常用大写字母粗体表示\n",
    "形状用(m,n)或m*n表示m行n列\n",
    "行列数量相同时称为**方阵(aquare matrix)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac25d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12).reshape(3,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722e704",
   "metadata": {},
   "source": [
    "转置矩阵：将矩阵的行列交换\n",
    "Bij = Aji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3ab5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8],\n",
       "        [ 1,  5,  9],\n",
       "        [ 2,  6, 10],\n",
       "        [ 3,  7, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e3741",
   "metadata": {},
   "source": [
    "对称矩阵：特殊的方阵，其转置矩阵等于本身\n",
    "Aij = Aji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b78c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1,2,3], [2,0,4], [3,4,5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3683c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8d69c",
   "metadata": {},
   "source": [
    "## 张量\n",
    "\n",
    "**张量**：多维数组，本章只代数对象\n",
    "例如：在图像处理中，图像以n维数组的形式出现，三个轴对应高、宽、通道（表示颜色）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d10bc7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2,3,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c8594",
   "metadata": {},
   "source": [
    "**按元素**运算：\n",
    "- 一元运算：不会改变自身形状\n",
    "- 二元运算：两个相同形状的张量计算，结果保持相同形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb65d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone() # 复制\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688055ee",
   "metadata": {},
   "source": [
    "**哈达玛积(Hadamard积)**：又称为**逐元素乘法**、**元素-wise乘法**，两个相同形状的张量按元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8132a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e80133",
   "metadata": {},
   "source": [
    "张量乘或加上一个标量不会改变形状：张量每个元素都与标量加或乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fff6714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4, 2, 3, 4]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "(a+X, a*X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db380ce",
   "metadata": {},
   "source": [
    "## 求和/均值\n",
    "\n",
    "求和**sum()**：计算个元素之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2166bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量求和\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "(x, x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d89ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), tensor(190.))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 任意形状的张量求和\n",
    "(A.shape, A.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff62e6",
   "metadata": {},
   "source": [
    "默认情况下，求和函数会沿着所有轴方向降低张量的维度，使其变为一个标量\n",
    "也可以指定一个轴来降低维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8a684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着轴0降维：求和所有行\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a92345de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着轴1降维：求和所有列\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55527621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着轴0和1求和：对于矩阵而言就是对每个元素求和\n",
    "A.sum(axis=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb928512",
   "metadata": {},
   "source": [
    "**平均值(mean或average)**：总和除以元素总个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec9eb4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum()/A.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f47312",
   "metadata": {},
   "source": [
    "同样也可以沿着指定轴计算平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "653f5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0)/A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01976e",
   "metadata": {},
   "source": [
    "非降维运算：计算求和或均值时，不希望改变维度个数，可指定keepdims属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc096665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c751cd",
   "metadata": {},
   "source": [
    "由于sum_A保持两个轴，可以通过广播对A和sum_A计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a63975f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aba5f7",
   "metadata": {},
   "source": [
    "## 点积\n",
    "\n",
    "**点积(Dot Product)**：又称为**数量积**，两个向量之间先按元素相乘，得到的向量进行求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d43053a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "x, y, torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e50db",
   "metadata": {},
   "source": [
    "## 矩阵-向量积\n",
    "\n",
    "**矩阵-向量积(matrix-vector product)**：A(m,n)和x(n)计算向量积，把矩阵A看成列向量，每个元素是长度n的行向量，将列向量的每个元素与x计算数量积，得到长度m的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce21eb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5,4)\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "A.shape, x.shape, torch.mv(A,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f0d67",
   "metadata": {},
   "source": [
    "## 矩阵-矩阵乘法\n",
    "\n",
    "**矩阵乘法**：A(m,k)和B(k,n)计算矩阵乘法，把B看成行向量，每个元素为列向量，让A与B的每个列向量做向量积，得到矩阵C(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47c04b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "torch.mm(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5b257",
   "metadata": {},
   "source": [
    "## 范数\n",
    "\n",
    "**范数**：表示张量的大小，不是指维度，而是分量\n",
    "**向量范数**：将向量映射到标量的函数f\n",
    "**向量范数性质**：\n",
    "- f(ax) = |a|f(x)\n",
    "- 三角不等式：f(x+y) <= f(x) + f(y)\n",
    "- 非负： f(x) >= 0\n",
    "- 仅在所有元素为0时，范数才为0\n",
    "\n",
    "**L2范数**：**欧几里得距离**，每个元素平方 -> 求和 -> 算术平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c2b1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([4.0, -3.0])\n",
    "torch.norm(u) # L2范数、欧几里得距离"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ab516",
   "metadata": {},
   "source": [
    "深度学习中更常用L2范数平方的平方\n",
    "偶尔也会用到**L1范数**：向量元素绝对值之和\n",
    "相比于L2范数，L1的异常值的影响较小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d25995ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c49d4",
   "metadata": {},
   "source": [
    "L1和L2范数可以看成Lp范数的特例\n",
    "**Lp范数**：每个元素绝对值p次方 -> 求和 -> 开p次根\n",
    "\n",
    "对于各个维度的张量都适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8730826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones(4,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd9689",
   "metadata": {},
   "source": [
    "**范数的目标**：最大化分配给数据的概率，最小化预测值与真实值的差距。即最小化相似项目的距离，最大化不同项目的距离"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
